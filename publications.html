<!DOCTYPE html>
<html>

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-164479100-1"></script>
    <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-164479100-1');







    </script>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>RAIVN Lab - Publications</title>
    <meta name="description" content="RAIVN Lab -- Publications.">
    <link rel="stylesheet" href="./css/main.css">
    <link rel="stylesheet" href="./css/styles.css">
    <link rel="canonical" href="./publications.html">
    <link rel="shortcut icon" type="image/x-icon" href="./images/favicon.ico">


</head>


<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container-fluid">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
                    data-target="#navbar-collapse-1" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <a class="navbar-brand" href="./index.html" style="color:black">RAIVN Lab @ UW</a>
        </div>
        <div class="collapse navbar-collapse" id="navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li><a href="./index.html" class="navbar-item-text">Home</a></li>
                <li><a href="./people.html" class="navbar-item-text">People</a></li>
                <li><a href="./publications.html" class="navbar-item-text navbar-item-on">Publications</a></li>
                <li><a href="./resources.html" class="navbar-item-text">Resources</a></li>
                <li><a href="./news_archive.html" class="navbar-item-text">News Archive</a></li>
                <li><a href="https://sites.google.com/cs.washington.edu/uwcseali" target="_blank" class="navbar-item-text">Internal</a></li>
            </ul>
        </div>
    </div>
</div>

<div class="container-fluid">
    <div class="row">
        <div id="gridid" class="col-sm-12">
            <h2>Featured</h2>
            <div id="carousel" class="carousel slide" data-ride="carousel" data-interval="5000" data-pause="hover">
                <div class="carousel-inner" id="pub-page-carousel-inner">
                    <div class="item active center-cropped">
                        <a href="https://github.com/KuoHaoZeng/Visual_Reaction">
                            <div class="carousel-img-title">Visual Reaction:<br/>Learning to Play Catch with Your Drone</div>
                            <div class="center-cropped-img" style="background-image: url(./images/paperpic/drone_dataset_cropped.jpg)"></div>
                        </a>
                    </div>
                    <div class="item center-cropped">
                        <a href="https://keunhong.com/publications/photoshape/">
                            <div class="carousel-img-title">PhotoShape: Photorealistic Materials for<br/>Large-Scale Shape Collections</div>
                            <div class="center-cropped-img" style="background-image: url(./images/paperpic/keunhong_chairs.jpg)"></div>
                        </a>
                    </div>
                    <div class="item center-cropped">
                        <a href="https://danielgordon10.github.io/papers/vince.html">
                            <div class="carousel-img-title">Watching the World Go By:<br/>Representation Learning from Unlabeled Videos</div>
                            <div class="center-cropped-img" style="background-image: url(./images/paperpic/vince_cropped.jpg)"></div>
                        </a>
                    </div>
                    <div class="item center-cropped">
                        <a href="https://visualcommonsense.com/">
                            <div class="carousel-img-title">From Recognition to Cognition:<br/>Visual Commonsense Reasoning</div>
                            <div class="center-cropped-img" style="background-image: url(./images/paperpic/vcr.png)"></div>
                        </a>
                    </div>
                </div>
                <a class="left carousel-control" href="#carousel" role="button" data-slide="prev">
                    <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>
                    <span class="sr-only">Previous</span>
                </a>
                <a class="right carousel-control" href="#carousel" role="button" data-slide="next">
                    <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span>
                    <span class="sr-only">Next</span>
                </a>
            </div>
            <h2>2020</h2>
            <ul>
                <li class="publication"><b>Probing Text Models for Common Ground with Visual Representations</b><br/>
                    <i>Gabriel Ilharco, Rowan Zellers, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <a href="https://arxiv.org/abs/2005.00619">pdf</a>
                </li>
                <li class="publication"><b>Visual Commonsense Graphs: Reasoning about the Dynamic Context of a Still Image</b><br/>
                    <i>Jae Sung Park, Chandra Bhagavatula, Roozbeh Mottaghi, Ali Farhadi, Yejin Choi</i><br/>
                    <a href="https://arxiv.org/abs/2004.10796">pdf</a> |
                    <a href="https://visualcomet.xyz">project page</a>
                </li>

                <li class="publication"><b>Evaluating Machines by their Real-World Language Use</b><br/>
                    <i>Rowan Zellers, Ari Holtzman, Elizabeth Clark, Lianhui Qin, Ali Farhadi, Yejin Choi</i><br/>
                    <a href="arXiv:2004.03607">pdf</a> |
                    <a href="https://rowanzellers.com/advice/">project page</a>
                </li>

                <li class="publication"><b>Grounded Situation Recognition</b><br/>
                    <i>Sarah Pratt, Mark Yatskar, Luca Weihs, Ali Farhadi, Aniruddha Kembhavi</i><br/>
                    <a href="https://arxiv.org/abs/2003.12058">pdf</a> |
                    <a href="https://prior.allenai.org/projects/gsr">project page</a>
                </li>

                <li class="publication"><b>Watching the World Go By: Representation Learning from Unlabeled
                    Videos</b><br/>
                    <i>Daniel Gordon, Kiana Ehsani, Dieter Fox, Ali Farhadi</i><br/>
                    <a href="https://arxiv.org/abs/2003.07990">pdf</a> |
                    <a href="https://danielgordon10.github.io/papers/vince.html">project page</a> |
                    <a href="https://github.com/danielgordon10/vince">code</a>
                </li>

                <li class="publication"><b>Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping</b><br/>
                    <i>Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali Farhadi, Hannaneh Hajishirzi, Noah
                        Smith</i><br/>
                    <a href="https://arxiv.org/abs/2002.06305">pdf</a>
                </li>

                <li class="publication"><b>Soft Threshold Weight Reparameterization for Learnable Sparsity</b><br/>
                    <i>Aditya Kusupati, Vivek Ramanujan*, Raghav Somani*, Mitchell Wortsman*, Prateek Jain, Sham Kakade, Ali Farhadi</i><br/>
                    <b>ICML 2020</b><br/>
                    <a href="https://arxiv.org/abs/2002.03231">pdf</a> |
                    <a href="https://github.com/RAIVNLab/STR">code</a>
                </li>

                <li class="publication"><b>What’s Hidden in a Randomly Weighted Neural Network?</b><br/>
                    <i>Vivek Ramanujan*, Mitchell Wortsman*, Aniruddha Kembhavi, Ali Farhadi, Mohammad
                        Rastegari </i><br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/1911.13299">pdf</a> |
                    <a href="https://github.com/allenai/hidden-networks">code</a>
                </li>

                <li class="publication"><b>RoboTHOR: An Open Simulation-to-Real Embodied AI Platform</b><br/>
                    <i>Matt Deitke, Winson Han, Alvaro Herrasti, Aniruddha Kembhavi, Eric Kolve, Roozbeh
                        Mottaghi, Jordi Salvador, Dustin Schwenk, Eli VanderBilt, Mathew Walingford, Luca Weihs,
                        Mark Yatskar, Ali Farhadi</i> <br/>
                    <b>CVPR 2020</b></i><br/>
                    <a href="https://arxiv.org/abs/2004.06799">pdf</a> |
                    <a href="https://ai2thor.allenai.org/robothor/">project page</a>
                </li>

                <li class="publication"><b>Visual Reaction: Learning to Play Catch with Your Drone</b><br/>
                    <i>Kuo-Hao Zeng, Roozbeh Mottaghi, Luca Weihs, Ali Farhadi </i> <br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/1912.02155">pdf</a> |
                    <a href="http://github.com/KuoHaoZeng/Visual_Reaction">code</a>
                </li>

                <li class="publication"><b>Butterfly Transform: An Efficient FFT Based Neural Architecture
                    Design</b><br/>
                    <i>Keivan Alizadeh vahid, Anish Prabhu, Ali Farhadi, Mohammad Rastegari</i><br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/1906.02256">pdf</a> |
                    <a href="https://github.com/keivanalizadeh/ButterflyTransform">code</a>
                </li>

                <li class="publication"><b>Use the Force, Luke! Learning to Predict Physical Forces by Simulating
                    Effects</b><br/>
                    <i>Kiana Ehsani, Shubham Tulsiani, Saurabh Gupta, Ali Farhadi, Abhinav Gupta</i><br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/2003.12045">pdf</a> |
                    <a href="https://ehsanik.github.io/forcecvpr2020/">project page</a> |
                    <a href="https://github.com/ehsanik/touchTorch">code</a>
                </li>

                <li class="publication"><b>ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks</b><br/>
                    <i>Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, Dieter Fox</i><br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/1912.01734">pdf</a> |
                    <a href="https://askforalfred.com/">project page</a> |
                    <a href="https://github.com/askforalfred/alfred">code</a>
                </li>
            </ul>
            <h2>2019</h2>
            <ul>
                <li class="publication"><b>Discovering Neural Wirings</b><br/>
                    <i>Mitchel Wortsman, Ali Farhadi, Mohammad Rastegari</i><br/>
                    <b>NeurIPS 2019</b><br/>
                    <a href="https://arxiv.org/abs/1906.00586">pdf</a> |
                    <a href="https://prior.allenai.org/projects/discovering-neural-wirings">project page</a> |
                    <a href="https://github.com/allenai/dnw">code</a> |
                    <a href="https://mitchellnw.github.io/blog/2019/dnw/">blog</a>
                </li>
                <li class="publication"><b>Defending Against Neural Fake news</b><br/>
                    <i>Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, Yejin Choi</i><br/>
                    <b>NeurIPS 2019</b><br/>
                    <a href="https://arxiv.org/abs/1905.12616">pdf</a> |
                    <a href="https://rowanzellers.com/grover/">project page</a> |
                    <a href="http://github.com/rowanz/grover">code</a> |
                    <a href="https://grover.allenai.org/">demo</a> |
                    <a href="https://medium.com/ai2-blog/counteracting-neural-disinformation-with-grover-6cf6690d463b">blog</a>
                </li>
                <li class="publication"><b>Conditional Driving from Natural Language Instructions</b><br/>
                    <i>Junha Roh, Chris Paxton, Andrezej Pronobis, Ali Farhadi, Dieter Fox</i><br/>
                    <b>CoRL 2019</b><br/>
                    <a href="https://arxiv.org/abs/1910.07615">pdf</a> |
                    <a href="https://sites.google.com/view/language-grounded-driving">project page</a> |
                    <a href="https://github.com/rohjunha/language-grounded-driving">code</a>
                </li>
                <li class="publication"><b>Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index</b><br/>
                    <i>Minjoon Seo, J Lee, Tom Kwiatkowski, AP Parikh, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>ACL 2019</b><br/>
                    <a href="https://arxiv.org/abs/1906.05807">pdf</a> |
                    <a href="https://github.com/uwnlp/denspi">code</a>
                </li>
                <li class="publication"><b>HellaSwag: Can a Machine Really Finish Your Sentence?</b><br/>
                    <i>Rowan Zellers, A Holtzman, Yonatan Bisk, Ali Farhadi, Yejin Choi</i><br/>
                    <b>ACL 2019</b><br/>
                    <a href="https://arxiv.org/abs/1905.07830">pdf</a> |
                    <a href="https://rowanzellers.com/hellaswag/">project page</a> |
                    <a href="https://github.com/rowanz/hellaswag">code</a>
                </li>
                <li class="publication"><b>Learning to Learn How to Learn:Self-Adaptive Visual Navigation Using Meta-Learning</b><br/>
                    <i>Mitchell Wortsman, Kiana Ehsani, Mohammad Rastegari, Ali Farhadi, Roozbeh Mottaghi</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1812.00971">pdf</a> |
                    <a href="https://github.com/allenai/savn">code</a>
                </li>
                <li class="publication"><b>From Recognition to Cognition: Visual Commonsense Reasoning</b><br/>
                    <i>Rowan Zellers, Yonatan Bisk, Ali Farhadi, Yejin Choi</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1811.10830">pdf</a> |
                    <a href="https://visualcommonsense.com/">project page</a> |
                    <a href="https://github.com/rowanz/r2c/">code</a>
                </li>
                <li class="publication"><b>OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge</b><br/>
                    <i>Kenneth Marino, Mohammad Rastegari, Ali Farhadi, Roozbeh Mottaghi</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1906.00067">pdf</a>
                </li>
                <li class="publication"><b>Video Relationship Reasoning using Gated Spatio-Temporal Energy Graph</b><br/>
                    <i>Yao-Hung Hubert Tsai, Santosh Divvala, Louis-Philippe Morency, Ruslan Salakhutdinov, Ali Farhadi</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1903.10547">pdf</a>
                </li>
                <li class="publication"><b>ELASTIC: Improving CNNs with Instance Specific Scaling Policies</b><br/>
                    <i>Huiyu Wang, Aniruddha Kembhavi, Ali Farhadi, Alan Yuille, Mohammad Rastegari</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1812.05262">pdf</a>
                </li>
                <li class="publication"><b>Two Body Problem: Collaborative Visual Task Completion</b><br/>
                    <i>Unnat Jain, Luca Weihs, Eric Kolve, Mohammad Rastegari, Svetlana Lazebnik, Ali Farhadi, Alexander Schwing, Aniruddha Kembhavi</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1904.05879">pdf</a>
                </li>
                <li class="publication"><b>SplitNet: Sim2Sim and Task2Task Transfer for Embodied Visual Navigation</b><br/>
                    <i>Daniel Gordon, Abhishek Kadian, Devi Parikh, Judy Hoffman, Dhruv Batra</i><br/>
                    <b>ICCV 2019</b><br/>
                    <a href="https://danielgordon10.github.io/pdfs/splitnet.pdf">pdf</a> |
                    <a href="https://github.com/facebookresearch/splitnet">code</a>
                </li>
                <li class="publication"><b>Shifting the Baseline: Single Modality Performance on Visual Navigation & QA</b><br/>
                    <i>Jesse Thomason, Daniel Gordon, Yonatan Bisk</i><br/>
                    <b>NAACL 2019 Short Papers</b><br/>
                    <a href="https://danielgordon10.github.io/pdfs/shifting_baseline.pdf">pdf</a>
                </li>
                <li class="publication"><b>Visual Semantic Navigation using Scene Priors</b><br/>
                    <i>Wei Yang, Xiaolong Wang, Ali Farhadi, Abhinav Gupta, Roozbeh Mottaghi</i><br/>
                    <b>ICLR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1810.06543">pdf</a>
                </li>
            </ul>
            <h2>2018</h2>
            <ul>
                <li class="publication"><b>What Should I Do Now? Marrying Reinforcement Learning and Symbolic Planning</b><br/>
                    <i>Daniel Gordon, Dieter Fox, Ali Farhadi</i><br/>
                    <a href="https://danielgordon10.github.io/pdfs/hiprl.pdf">pdf</a> |
                    <a href="https://danielgordon10.github.io/papers/hiprl.html">project page</a> |
                    <a href="https://www.youtube.com/watch?v=0TtWJ_0mPfI">video</a>
                </li>
                <li class="publication"><b>Label refinery: Improving imagenet classification through label progression</b><br/>
                    <i>Hessam Bagherinezhad, Maxwell Horton, Mohammad Rastegari, Ali Farhadi</i><br/>
                    <a href="https://arxiv.org/abs/1805.02641">pdf</a> |
                    <a href="https://github.com/hessamb/label-refinery">code</a>
                </li>
                <li class="publication"><b>YOLOv3: An Incremental Improvement</b><br/>
                    <i>Joseph Redmon, Ali Farhadi</i><br/>
                    <a href="https://arxiv.org/abs/1804.02767">pdf</a> |
                    <a href="https://pjreddie.com/darknet/yolo/">project page</a> |
                    <a href="https://www.youtube.com/watch?v=MPU2HistivI">video</a>
                </li>
                <li class="publication"><b>Phrase-Indexed Question Answering: A New Challenge for Scalable Document Comprehension</b><br/>
                    <i>Minjoon Seo, Tom Kwiatkowski, Ankur P. Parikh, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>EMNLP 2018</b><br>
                    <a href="https://arxiv.org/abs/1804.07726">pdf</a> |
                    <a href="https://github.com/uwnlp/piqa">code</a>
                </li>
                <li class="publication"><b>PhotoShape: Photorealistic Materials for Large-Scale Shape Collections</b><br/>
                    <i>Keunhong Park, Konstantinos Rematas, Ali Farhadi, Steve Seitz</i><br/>
                    <b>SIGGRAPH Asia 2018</b><br>
                    <a href="https://arxiv.org/abs/1809.09761">pdf</a> |
                    <a href="https://keunhong.com/publications/photoshape/">project page</a> |
                    <a href="https://github.com/keunhong/photoshape">code</a>
                </li>
                <li class="publication"><b>Imagine This! Scripts to Compositions to Videos</b><br/>
                    <i>Tanmay Gupta, Dustin Schwenk, Ali Farhadi, Derek Hoiem, Aniruddha Kembhavi</i><br/>
                    <b>ECCV 2018</b><br/>
                    <a href="https://arxiv.org/abs/1804.03608">pdf</a>
                </li>
                <li class="publication"><b>Transferring Common-Sense Knowledge for Object Detection</b><br/>
                    <i>Krishna Kumar Singh, Santosh Kumar Divvala, Ali Farhadi, Yong Jae Lee</i><br/>
                    <b>ECCV 2019</b><br/>
                    <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Krishna_Kumar_Singh_Transferring_Common-Sense_Knowledge_ECCV_2018_paper.pdf">pdf</a>
                </li>
                <li class="publication"><b>Who Let The Dogs Out? Modeling Dog Behavior From Visual Data</b><br/>
                    <i>Kiana Ehsani, Hessam Bagherinezhad, Joseph Redmon, Roozbeh Mottaghi, Ali Farhadi</i><br/>
                    <b>CVPR 2018</b><br>
                    <a href="https://arxiv.org/abs/1803.10827">pdf</a> |
                    <a href="https://github.com/ehsanik/dogTorch">code</a>
                </li>
                <li class="publication"><b>Segan: Segmenting and generating the invisible</b><br/>
                    <i>Kiana Ehsani, Roozbeh Mottaghi, Ali Farhadi</i><br/>
                    <b>CVPR 2018</b><br>
                    <a href="https://arxiv.org/abs/1703.10239">pdf</a> |
                    <a href="https://github.com/ehsanik/SeGAN">code</a>
                </li>
                <li class="publication"><b>Actor and Observer: Joint Modeling of First and Third-Person Videos</b><br/>
                    <i>Gunnar Sigurdsson, Abhinav Gupta, Cordelia Schmid, Ali Farhadi, Karteek Alahari</i><br/>
                    <b>CVPR 2018</b><br>
                    <a href="https://arxiv.org/abs/1804.09627">pdf</a>
                </li>
                <li class="publication"><b>Structured Set Matching Networks for One-Shot Part Labeling</b><br/>
                    <i>Jonghyun Choi, Jayant Krishnamurthy, Aniruddha Kembhavi, Ali Farhadi</i><br/>
                    <b>CVPR 2018</b><br>
                    <a href="https://arxiv.org/abs/1712.01867">pdf</a>
                </li>
                <li class="publication"><b>IQA: Visual Question Answering in Interactive Environments</b><br/>
                    <i>Daniel Gordon, Aniruddha Kembhavi, Mohammad Rastegari, Joseph Redmon, Dieter Fox, Ali Farhadi</i><br/>
                    <b>CVPR 2018</b> | <font style="color:green"><b>NVIDIA Pioneering Research Award</b></font><br/>
                    <a href="https://danielgordon10.github.io/pdfs/iqa.pdf">pdf</a> |
                    <a href="https://danielgordon10.github.io/papers/iqa.html">project page</a> |
                    <a href="https://github.com/danielgordon10/thor-iqa-cvpr-2018">code</a> |
                    <a href="https://www.youtube.com/watch?v=pXd3C-1jr98">video</a>
                </li>
                <li class="publication"><b>Neural Speed Reading via Skim-RNN</b><br/>
                    <i>Minjoon Seo, Sewon Min, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>ICLR 2018</b><br>
                    <a href="https://arxiv.org/abs/1711.02085">pdf</a>
                </li>
                <li class="publication"><b>Re3: Real-Time Recurrent Regression Networks for Visual Tracking of Generic Objects</b><br/>
                    <i>Daniel Gordon, Ali Farhadi, Dieter Fox</i><br/>
                    <b>RAL 2018</b> | Presented at ICRA 2018<br/>
                    <a href="https://danielgordon10.github.io/pdfs/re3.pdf">pdf</a> |
                    <a href="https://danielgordon10.github.io/papers/re3.html">project page</a> |
                    <a href="https://gitlab.com/danielgordon10/re3-tensorflow">code</a> |
                    <a href="https://www.youtube.com/watch?v=RByCiOLlxug">video</a> |
                    <a href="https://www.youtube.com/watch?v=mRpvhuuwMiY">GTC Talk</a>
                </li>
                <li class="publication"><b>AJILE Movement Prediction: Multimodal Deep Learning for Natural Human Neural Recordings and Video</b><br/>
                    <i>Nancy Xin Ru Wang, Ali Farhadi, Rajesh Rao, Bingni Brunton</i><br/>
                    <b>AAAI 2018</b><br>
                    <a href="https://arxiv.org/abs/1709.05939">pdf</a>
                </li>
            </ul>
            <h2>2017</h2>
            <ul>
                <li class="publication"><b>AI2-THOR: An Interactive 3D Environment for Visual AI</b><br/>
                    <i>Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt, Luca Weihs, Alvaro Herrasti, Daniel Gordon, Yuke Zhu, Abhinav Gupta, Ali Farhadi</i><br/>
                    <a href="https://arxiv.org/abs/1712.05474">pdf</a> |
                    <a href="https://ai2thor.allenai.org/">project page</a> |
                    <a href="https://github.com/allenai/ai2thor">code</a> |
                    <a href="https://www.youtube.com/watch?v=KcELPpdN770">video</a> |
                    <a href="https://ai2thor.allenai.org/demo/">demo</a>
                </li>
                <li class="publication"><b>Visual Semantic Planning using Deep Successor Representations</b><br/>
                    <i>Daniel Gordon*, Yuke Zhu*, Eric Kolve, Dieter Fox, Li Fei-Fei, Abhinav Gupta, Roozbeh Mottaghi, Ali Farhadi</i><br/>
                    <b>ICCV 2017</b><br/>
                    <a href="https://danielgordon10.github.io/pdfs/vsp.pdf">pdf</a> |
                    <a href="https://www.youtube.com/watch?v=_2pYVw6ATKo">video</a>
                </li>
                <li class="publication"><b>See the Glass Half Full: Reasoning about Liquid Containers, their Volume and Content</b><br/>
                    <i>Roozbeh Mottaghi, Connor Schenck, Dieter Fox, Ali Farhadi</i><br/>
                    <b>ICCV 2017</b><br/>
                    <a href="https://arxiv.org/abs/1701.02718">pdf</a>
                </li>
                <li class="publication"><b>YOLO9000: Better, Faster, Stronger</b><br/>
                    <i>Joseph Redmon, Ali Farhadi</i><br/>
                    <b>CVPR 2017</b> | <font style="color:green"><b>Best Paper Honorable Mention</b></font><br/>
                    <a href="https://arxiv.org/abs/1612.08242">pdf</a> |
                    <a href="https://pjreddie.com/darknet/yolo/">project page</a>
                </li>
                <li class="publication"><b>Are You Smarter Than A Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension</b><br/>
                    <i>Aniruddha Kembhavi, Minjoon Seo, Eric Klove, Dustin Schwenk, Hannaneh Hajishirzi, Ali Farhadi</i><br/>
                    <b>CVPR 2017</b><br/>
                    <a href="http://ai2-website.s3.amazonaws.com/publications/CVPR17_TQA.pdf">pdf</a> |
                    <a href="http://vuchallenge.org/tqa.html">project page</a>
                </li>
                <li class="publication"><b>LCNN: Lookup-based Convolutional Neural Network</b><br/>
                    <i>Hessam Bagherinezhad, Mohammad Rastegari, Ali Farhadi</i><br/>
                    <b>CVPR 2017</b><br/>
                    <a href="https://arxiv.org/abs/1611.06473">pdf</a> |
                    <a href="https://github.com/hessamb/lcnn">code</a>
                </li>
                <li class="publication"><b>Commonly Uncommon: Semantic Sparsity in Situation Recognition</b><br/>
                    <i>Mark Yatskar, Vicente Ordóñez, Luke Zettlemoyer, Ali Farhadi</i><br/>
                    <b>CVPR 2017</b><br/>
                    <a href="https://arxiv.org/abs/1612.00901">pdf</a> |
                    <a href="http://imsitu.org/demo/">demo</a>
                </li>
                <li class="publication"><b>Asynchronous Temporal Fields for Action Recognition</b><br/>
                    <i>Gunnar A Sigurdsson, Santosh Divvala, Ali Farhadi, Abhinav Gupta</i><br/>
                    <b>CVPR 2017</b><br/>
                    <a href="https://arxiv.org/abs/1612.06371">pdf</a>
                </li>
                <li class="publication"><b>Query-Reduction Networks for Question Answering</b><br/>
                    <i>Minjoon Seo, Sewon Min, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>ICLR 2017</b><br/>
                    <a href="https://arxiv.org/abs/1606.04582">pdf</a> |
                    <a href="https://github.com/uwnlp/qrn">code</a>
                </li>
                <li class="publication"><b>Bidirectional Attention Flow for Machine Comprehension</b><br/>
                    <i>Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>ICLR 2017</b><br/>
                    <a href="https://arxiv.org/abs/1611.01603">pdf</a> |
                    <a href="https://allenai.github.io/bi-att-flow/"> project page</a> |
                    <a href="https://github.com/allenai/bi-att-flow">code</a>
                </li>
                <li class="publication"><b>Target-driven visual navigation in indoor scenes using deep reinforcement learning</b><br/>
                    <i>Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph Lim, Abhinav Gupta, Fei-Fei Li, Ali Farhadi</i><br/>
                    <b>ICRA 2017</b><br/>
                    <a href="https://arxiv.org/abs/1609.05143">pdf</a>
                </li>
                <li class="publication"><b>Summarizing unconstrained videos using salient montages</b><br/>
                    <i>Min Sun, Ali Farhadi, Ben Taskar, Steve Seitz</i><br/>
                    <b>TPAMI 2017</b><br/>
                    <a href="https://ieeexplore.ieee.org/document/7779036">pdf</a>
                </li>
                <li class="publication"><b>Semantic Highlight Retrieval and Term Prediction</b><br/>
                    <i>Min Sun , Kuo-Hao Zeng, Yen-Chen Lin, Ali Farhadi</i><br/>
                    <b>TIP 2017</b><br/>
                    <a href="https://ieeexplore.ieee.org/document/7852483">pdf</a>
                </li>
            </ul>
            <h2>2016</h2>
            <ul>
                <li class="publication"><b>XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</b><br/>
                    <i>Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, Ali Farhadi</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="http://arxiv.org/abs/1603.05279">pdf</a> |
                    <a href="https://github.com/allenai/XNOR-Net">code</a>
                </li>
                <li class="publication"><b>Deep3D: Fully Automatic 2D-to-3D Video Conversion with Deep Convolutional Neural Networks</b><br/>
                    <i>Junyuan Xie, Ross B. Girshick, Ali Farhadi</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="https://arxiv.org/abs/1604.03650">pdf</a> |
                    <a href="https://github.com/piiswrong/deep3d">code</a>
                </li>
                <li class="publication"><b>A Diagram Is Worth A Dozen Images</b><br/>
                    <i>Ani Kembhavi, Mike Salvato, Eric Kolve, Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="https://arxiv.org/abs/1603.07396">pdf</a> |
                    <a href="https://github.com/allenai/dqa-net">code</a>
                </li>
                <li class="publication"><b>"What happens if..." Learning to predict the effect of forces in images</b><br/>
                    <i>Roozbeh Mottaghi, Mohammad Rastegari, Abhinav Gupta, Ali Farhadi</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="https://arxiv.org/abs/1603.05600">pdf</a>
                </li>
                <li class="publication"><b>Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding</b><br/>
                    <i>Gunnar Sigurdsson, Gul Varol, Xiaolong Wang, Ali Farhadi, Ivan Laptev, Abhinav Gupta</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="https://arxiv.org/abs/1604.01753">pdf</a> |
                    <a href="http://allenai.org/plato/charades/">project page</a>
                </li>
                <li class="publication"><b>FigureSeer:Parsing Result-Figures in Research Papers</b><br/>
                    <i>Noah Siegel, Santosh Divvala, Ali Farhadi</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="http://ai2-website.s3.amazonaws.com/publications/Siegel16eccv.pdf">pdf</a> |
                    <a href="https://prior.allenai.org/projects/figureseer">project page</a>
                </li>
                <li class="publication"><b>You Only Look Once: Unified, Real-Time Object Detection</b><br/>
                    <i>Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi</i><br/>
                    <b>CVPR 2016</b> | <font style="color:green"><b>OpenCV People's Choice Award</b></font><br/>
                    <a href="http://arxiv.org/abs/1506.02640">pdf</a> |
                    <a href="https://pjreddie.com/darknet/yolo/">project page</a>
                </li>
                <li class="publication"><b>Situation Recognition: Visual Semantic Role Labeling for Image Understanding</b><br/>
                    <i>Mark Yatskar, Luke Zettlemoyer, Ali Farhadi</i><br/>
                    <b>CVPR 2016</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/SituationRecognition.pdf">pdf</a> |
                    <a href="https://github.com/my89/SituationCrf">code</a> |
                    <a href="https://github.com/my89/imSitu">dataset</a>
                </li>
                <li class="publication"><b>Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images</b><br/>
                    <i>Roozbeh Mottaghi, Hessam Bagherinezhad, Mohammad Rastegari, Ali Farhadi</i><br/>
                    <b>CVPR 2016</b><br/>
                    <a href="https://arxiv.org/abs/1511.04048">pdf</a> |
                    <a href="http://allenai.org/plato/newtonian-understanding/">project page</a>
                </li>
                <li class="publication"><b>Actions~Transformation</b><br/>
                    <i>Xiaolong Wang, Ali Farhadi, Abhinav Gupta</i><br/>
                    <b>CVPR 2016</b><br/>
                    <a href="https://arxiv.org/abs/1512.00795">pdf</a>
                </li>
                <li class="publication"><b>A Task-Oriented Approach for Cost-sensitive Recognition</b><br/>
                    <i>Roozbeh Mottaghi, Hannaneh Hajishirzi, Ali Farhadi</i><br/>
                    <b>CVPR 2016</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Tasks.pdf">pdf</a>
                </li>
                <li class="publication"><b>Unsupervised Deep Embedding for Clustering Analysis</b><br/>
                    <i>Junyuan Xie, Ross B. Girshick, Ali Farhadi</i><br/>
                    <b>ICML 2016</b><br/>
                    <a href="http://proceedings.mlr.press/v48/xieb16.html">pdf</a> |
                    <a href="https://github.com/piiswrong/dec">code</a>
                </li>
                <li class="publication"><b>Stating the Obvious: Extracting Visual Common Sense Knowledge</b><br/>
                    <i>Mark Yatskar, Vicente Ordóñez, Ali Farhadi</i><br/>
                    <b>NAACL 2016</b><br/>
                    <a href="https://www.aclweb.org/anthology/N16-1023">pdf</a>
                </li>
                <li class="publication"><b>Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects</b><br/>
                    <i>Hessam Bagherinezhad, Hannaneh Hajishirzi, Yejin Choi, Ali Farhadi</i><br/>
                    <b>AAAI 2016</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Abnormality.pdf">pdf</a>
                </li>
                <li class="publication"><b>Toward a Taxonomy and Computational Models of Abnormalities in Images</b><br/>
                    <i>Babak Saleh, Ahmed Elgammal, Jacob Feldman, Ali Farhadi</i><br/>
                    <b>AAAI 2016</b> | <font style="color:green"><b>Best Student Paper Award</b></font><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Tasks.pdf">pdf</a>
                </li>
            </ul>
            <h2>2015</h2>
            <ul>
                <li class="publication"><b>Segment-Phrase Table for Semantic Segmentation, Visual Entailment and Paraphrasing</b><br/>
                    <i>Hamid Izadinia, Fereshteh Sadeghi, Santosh K Divvala, Hannaneh Hajishirzi, Yejin Choi, Ali Farhadi</i><br/>
                    <b>ICCV 2015</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/spt.pdf">pdf</a>
                </li>
                <li class="publication"><b>Generating Notifications for Missing Actions: Don’t forget to turn the lights off!</b><br/>
                    <i>Bilge Soran, Ali Farhadi, Linda Shapiro</i><br/>
                    <b>ICCV 2015</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/alarm-iccv.pdf">pdf</a>
                </li>
                <li class="publication"><b>VISALOGY: Answering Visual Analogy Questions</b><br/>
                    <i>Fereshteh Sadeghi, Larry Zittnick, Ali Farhadi</i><br/>
                    <b>NeurIPS 2015</b><br/>
                    <a href="https://papers.nips.cc/paper/5777-visalogy-answering-visual-analogy-questions">pdf</a>
                </li>
                <li class="publication"><b>Real-Time Grasp Detection Using Convolutional Neural Networks</b><br/>
                    <i>Joseph Redmon, Anelia Angelova</i><br/>
                    <b>ICRA 2015</b><br/>
                    <a href="http://arxiv.org/abs/1506.02640">pdf</a>
                </li>
                <li class="publication"><b>Solving Geometry Problems: Combining Text and Diagram Interpretation</b><br/>
                    <i>Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi, Oren Etzioni, Clint Malcolm</i><br/>
                    <b>EMNLP 2015</b><br/>
                    <a href="https://www.aclweb.org/anthology/D15-1171">pdf</a> |
                    <a href="https://geometry.allenai.org/">project page</a>
                </li>
                <li class="publication"><b>VisKE: Visual Knowledge Extraction and Question Answering by Visual Verification of Relation Phrases</b><br/>
                    <i>Fereshteh Sadeghi, Santosh K Divvala, Ali Farhadi</i><br/>
                    <b>CVPR 2015</b><br/>
                    <a href="http://viske.allenai.org/paper/fsadeghi_VisKE.pdf">pdf</a> |
                    <a href="http://viske.allenai.org/">project page</a>
                </li>
                <li class="publication"><b>Discriminative and Consistent Similarities in Instance-Level Multiple Instance Learning</b><br/>
                    <i>Mohammad Rastegari, Hannaneh Hajishirzi, Ali Farhadi</i><br/>
                    <b>CVPR 2015</b><br/>
                    <a href="http://ssli.ee.washington.edu/~hannaneh/papers/MIL.pdf">pdf</a>
                </li>
                <li class="publication"><b>Learning to Select and Order Vacation Photographs</b><br/>
                    <i>Fereshteh Sadeghi, J Rafael Tena, Ali Farhadi, Leonid Sigal</i><br/>
                    <b>WACV 2015</b><br/>
                    <a href="http://homes.cs.washington.edu/~fsadeghi/papers/fsadeghi_album_wacv15.pdf">pdf</a>
                </li>
            </ul>
            <h2>2014</h2>
            <ul>
                <li class="publication"><b>Diagram Understanding in Geometry Questions</b><br/>
                    <i>Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi, Oren Etzioni</i><br/>
                    <b>AAAI 2014</b><br/>
                    <a href="http://homes.cs.washington.edu/~minjoon/papers/geosolver/diagram_understanding.pdf">pdf</a> |
                    <a href="https://geometry.allenai.org/">project page</a>
                </li>
            </ul>

        </div>
    </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="./js/bootstrap.min.js"></script>


</body>

</html>
