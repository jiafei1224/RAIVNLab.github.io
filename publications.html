<!DOCTYPE html>
<html>

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-164479100-1"></script>
    <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-164479100-1');







    </script>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>RAIVN Lab - Publications</title>
    <meta name="description" content="RAIVN Lab -- Publications.">
    <link rel="stylesheet" href="./css/main.css">
    <link rel="stylesheet" href="./css/styles.css">
    <link rel="canonical" href="./publications.html">
    <link rel="shortcut icon" type="image/x-icon" href="./images-raivn/favicon.ico">


</head>


<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container-fluid">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
                    data-target="#navbar-collapse-1" aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <a class="navbar-brand" href="./index.html" style="color:black">RAIVN Lab @ UW</a>
        </div>
        <div class="collapse navbar-collapse" id="navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li><a href="./index.html" class="navbar-item-text">Home</a></li>
                <li><a href="./people.html" class="navbar-item-text">People</a></li>
                <li><a href="./publications.html" class="navbar-item-text navbar-item-on">Publications</a></li>
                <li><a href="./resources.html" class="navbar-item-text">Resources</a></li>
                <li><a href="./news_archive.html" class="navbar-item-text">News Archive</a></li>
                <li><a href="https://sites.google.com/cs.washington.edu/uwcseali" target="_blank" class="navbar-item-text">Internal</a></li>
            </ul>
        </div>
    </div>
</div>

<div class="container-fluid">
    <div class="row">
        <div id="gridid" class="col-sm-12">
            <!-- <h2>Featured</h2>
            <div id="carousel" class="carousel slide" data-ride="carousel" data-interval="5000" data-pause="hover">
                <div class="carousel-inner" id="pub-page-carousel-inner">
                    <div class="item active center-cropped">
                        <a href="https://mitchellnw.github.io/blog/2020/supsup/">
                            <div class="carousel-img-title">Supermasks in Superposition</div>
                            <div class="center-cropped-img" style="background-image: url(./images-raivn/paperpic/supsup.png)"></div>
                        </a>
                    </div>
                    <div class="item center-cropped">
                        <a href="https://prior.allenai.org/projects/interactive-visual-navigation">
                            <div class="carousel-img-title">Pushing it out of the Way:<br/>Interactive Visual Navigation</div>
                            <div class="center-cropped-img" style="background-image: url(./images-raivn/paperpic/interactive-visual-navigation.png)"></div>
                        </a>
                    </div>
                    <div class="item center-cropped">
                        <a href="https://github.com/ehsanik/muscleTorch">
                            <div class="carousel-img-title">What Can You Learn from Your Muscles?<br/>Learning Visual Representation from Human Interactions</div>
                            <div class="center-cropped-img" style="background-image: url(./images-raivn/paperpic/muscleTorch.png)"></div>
                        </a>
                    </div>
                    <div class="item center-cropped">
                        <a href="https://danielgordon10.github.io/papers/vince.html">
                            <div class="carousel-img-title">Watching the World Go By:<br/>Representation Learning from Unlabeled Videos</div>
                            <div class="center-cropped-img" style="background-image: url(./images-raivn/paperpic/vince_cropped.jpg)"></div>
                        </a>
                    </div>
                    <div class="item center-cropped">
                        <a href="https://openreview.net/forum?id=UuchYL8wSZo">
                            <div class="carousel-img-title">Learning Generalizable Visual Representations via Interactive Gameplay</div>
                            <div class="center-cropped-img" style="background-image: url(./images-raivn/paperpic/hide&seek.png)"></div>
                        </a>
                    </div>
                </div>
                <a class="left carousel-control" href="#carousel" role="button" data-slide="prev">
                    <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>
                    <span class="sr-only">Previous</span>
                </a>
                <a class="right carousel-control" href="#carousel" role="button" data-slide="next">
                    <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span>
                    <span class="sr-only">Next</span>
                </a>
            </div> -->
            <h2>Preprints</h2>
            <ul>
                <li class="publication"><b>Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time</b><br/>
                    <i>Mitchell Wortsman, Gabriel Ilharco, Samir Yitzhak Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari S. Morcos, Hongseok Namkoong, Ali Farhadi, Yair Carmon*, Simon Kornblith*, Ludwig Schmidt*</i><br/>
                    <a href="https://arxiv.org/abs/2203.05482">pdf</a>
                </li>
                <li class="publication"><b>The Introspective Agent: Interdependence of Strategy, Physiology, and Sensing for Embodied Agents</b><br/>
                    <i>Sarah Pratt, Luca Weihs, Ali Farhadi</i><br/>
                    <a href="https://arxiv.org/abs/2201.00411">pdf</a> |
                    <a href="https://github.com/sarahpratt/introspective">code</a>
                </li>
                <li class="publication"><b>LCS: Learning Compressible Subspaces for Adaptive Network Compression at Inference Time</b><br/>
                    <i>Elvis Nunez*, Maxwell Horton*, Anish Prabhu, Anurag Ranjan, Ali Farhadi, Mohammad Rastegari</i><br/>
                    <a href="https://arxiv.org/abs/2110.04252">pdf</a>
                </li>
            </ul>
            <h2>2022</h2>
            <ul>
                <li class="publication"><b>Robust fine-tuning of zero-shot models</b><br/>
                    <i>Mitchell Wortsman*, Gabriel Ilharco*, Jong Wook Kim, Mike Li, Simon Kornblith, Rebecca Roelofs, Raphael Gontijo Lopes, Hannaneh Hajishirzi, Ali Farhadi, Hongseok Namkoong, Ludwig Schmidt</i><br/>
                    <b>CVPR 2022</b><br/>
                    <a href="https://arxiv.org/abs/2109.01903">pdf</a>
                </li>
            </ul>
            <ul>
                <li class="publication"><b>MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound</b><br/>
                    <i>Rowan Zellers, Jiasen Lu, Ximing Lu, Youngjae Yu, Yanpeng Zhao, Mohammadreza Salehi, Aditya Kusupati, Jack Hessel, Ali Farhadi, Yejin Choi</i><br/>
                    <b>CVPR 2022</b><br/>
                    <a href="https://arxiv.org/abs/2201.02639">pdf</a> |
                    <a href="https://rowanzellers.com/merlotreserve">project page</a>
                </li>
            </ul>
            <ul>
                <li class="publication"><b>Forward Compatible Training for Representation Learning</b><br/>
                    <i>Vivek Ramanujan, Pavan Kumar Anasosalu Vasu, Ali Farhadi, Oncel Tuzel, Hadi Pouransari</i><br/>
                    <b>CVPR 2022</b><br/>
                    <a href="https://arxiv.org/abs/2112.02805">pdf</a>
                </li>
            </ul>
            <ul>
                <li class="publication"><b>ProtoSound: A Personalized and Scalable Sound Recognition System for Deaf and Hard-of-Hearing Users</b><br/>
                    <i>Dhruv Jain, Khoa Huynh Anh Nguyen, Steven Goodman, Rachel Grossman-Kahn, Hung Ngo, Aditya Kusupati, Ruofei Du, Alex Olwal, Leah Findlater, Jon E. Froehlich</i><br/>
                    <b>CHI 2022</b><br/>
                    <a href="https://arxiv.org/abs/2202.11134">pdf</a>
                </li>
            </ul>
            <h2>2021</h2>
            <ul>
                <li class="publication"><b>FiG-NeRF: Figure-Ground Neural Radiance Fields for 3D Object Category Modelling</b><br/>
                    <i>Christopher Xie, Keunhong Park, Ricardo Martin-Brualla, Matthew Brown</i><br/>
                    <b>3DV 2021</b><br/>
                    <a href="https://arxiv.org/abs/2104.08418">pdf</a> |
                    <a href="https://fig-nerf.github.io/">project page</a>
                </li>
                <li class="publication"><b>MERLOT: Multimodal Neural Script Knowledge Models</b><br/>
                    <i>Rowan Zellers, Ximing Lu, Jack Hessel, Youngjae Yu, Jae Sung Park, Jize Cao, Ali Farhadi, Yejin Choi</i><br/>
                    <b>NeurIPS 2021</b><br/>
                    <a href="https://arxiv.org/abs/2106.02636">pdf</a> |
                    <a href="https://rowanzellers.com/merlot/">project page</a>
                </li>
                <li class="publication"><b>LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes</b><br/>
                    <i>Aditya Kusupati, Matthew Wallingford, Vivek Ramanujan, Raghav Somani, Jae Sung Park, Krishna Pillutla, Prateek Jain, Sham Kakade, Ali Farhadi</i><br/>
                    <b>NeurIPS 2021</b><br/>
                    <a href="https://arxiv.org/abs/2106.01487">pdf</a> |
                    <a href="https://github.com/RAIVNLab/LLC">code</a>
                </li>
                <li class="publication"><b>LanguageRefer: Spatial-Language Model for 3D Visual Grounding</b><br/>
                    <i>Junha Roh, Karthik Desingh, Ali Farhadi, Dieter Fox</i><br/>
                    <b>CoRL 2021</b><br/>
                    <a href="https://arxiv.org/abs/2107.03438">pdf</a> |
                    <a href="https://sites.google.com/view/language-refer">project page</a>
                </li>
                <li class="publication"><b>HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields</b><br/>
                    <i>	Keunhong Park, Utkarsh Sinha, Peter Hedman, Jonathan T. Barron, Sofien Bouaziz, Dan B Goldman, Ricardo Martin-Brualla, Steven M. Seitz</i><br/>
                    <b>SIGGRAPH Asia 2021</b><br/>
                    <a href="https://arxiv.org/abs/2106.13228">pdf</a> |
                    <a href="https://hypernerf.github.io/">project page</a>
                </li>
                <li class="publication"><b>Finetuning Pretrained Transformers into RNNs</b><br/>
                    <i>	Jungo Kasai, Hao Peng, Yizhe Zhang, Dani Yogatama, Gabriel Ilharco, Nikolaos Pappas, Yi Mao, Weizhu Chen, Noah A Smith</i><br/>
                    <b>EMNLP 2021</b><br/>
                    <a href="https://arxiv.org/abs/2103.13076">pdf</a>
                </li>
                <li class="publication"><b>Parameter Norm Growth During Training of Transformers</b><br/>
                    <i>	William Merrill, Vivek Ramanujan, Yoav Goldberg, Roy Schwartz, Noah A. Smith</i><br/>
                    <b>EMNLP 2021</b><br/>
                    <a href="https://arxiv.org/abs/2010.09697">pdf</a>
                </li>
                <li class="publication"><b>Deformable Neural Radiance Fields</b><br/>
                    <i>Keunhong Park, Utkarsh Sinha, Jonathan T. Barron, Sofien Bouaziz, Dan B Goldman, Steven M. Seitz, Ricardo Martin-Brualla</i><br/>
                    <b>ICCV 2021</b><br/>
                    <a href="https://arxiv.org/abs/2011.12948">pdf</a> |
                    <a href="https://nerfies.github.io/">project page</a>
                </li>
                <li class="publication"><b>Contrasting Contrastive Self-Supervised Representation Learning Models</b><br/>
                    <i>	Klemen Kotar, Gabriel Ilharco, Ludwig Schmidt, Kiana Ehsani, Roozbeh Mottaghi</i><br/>
                    <b>ICCV 2021</b><br/>
                    <a href="https://arxiv.org/abs/2103.14005">pdf</a>
                </li>
                <li class="publication"><b>PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D World</b><br/>
                    <i>	Rowan Zellers, Ari Holtzman, Matthew Peters, Roozbeh Mottaghi, Aniruddha Kembhavi, Ali Farhadi, Yejin Choi</i><br/>
                    <b>ACL 2021</b><br/>
                    <a href="https://arxiv.org/abs/2106.00188">pdf</a>  |
                    <a href="https://rowanzellers.com/piglet/">project page</a>
                </li>
                <li class="publication"><b>Learning Neural Network Subspaces</b><br/>
                    <i>	Mitchell Wortsman, Maxwell Horton, Carlos Guestrin, Ali Farhadi, Mohammad Rastegari</i><br/>
                    <b>ICML 2021</b><br/>
                    <a href="https://arxiv.org/abs/2102.10472">pdf</a>  |
                    <a href="https://github.com/apple/learning-subspaces">code</a>
                </li>

                <li class="publication"><b>Probing Text Models for Common Ground with Visual Representations</b><br/>
                    <i>Gabriel Ilharco, Rowan Zellers, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>NAACL 2021</b><br/>
                    <a href="https://arxiv.org/abs/2005.00619">pdf</a>
                </li>

                <li class="publication"><b>TuringAdvice: A Generative and Dynamic Evaluation of Language Use</b><br/>
                    <i>Rowan Zellers, Ari Holtzman, Elizabeth Clark, Lianhui Qin, Ali Farhadi, Yejin Choi</i><br/>
                    <b>NAACL 2021</b><br/>
                    <a href="https://arxiv.org/abs/2004.03607">pdf</a> |
                    <a href="https://rowanzellers.com/advice/">project page</a>
                </li>

                <li class="publication"><b>Pushing it out of the Way: Interactive Visual Navigation</b><br/>
                    <i>Kuo-Hao Zeng, Luca Weihs, Ali Farhadi, Roozbeh Mottaghi</i><br/>
                    <b>CVPR 2021</b><br/>
                    <a href="https://arxiv.org/abs/2104.14040">pdf</a> |
                    <a href="https://prior.allenai.org/projects/interactive-visual-navigation">project page</a> |
                    <a href="https://github.com/KuoHaoZeng/Interactive_Visual_Navigation">code</a> |
                    <a href="https://youtu.be/q8xqxgnLEY4">video</a>
                </li>

                <li class="publication"><b>ManipulaTHOR: A Framework for Visual Object Manipulation</b><br/>
                    <i>Kiana Ehsani, Winson Han, Alvaro Herrasti, Eli VanderBilt, Eric Kolve, Luca Weihs, Aniruddha Kembhavi, Roozbeh Mottaghi</i><br/>
                    <b>CVPR 2021</b><br/>
                    <a href="https://arxiv.org/abs/2104.11213">pdf</a>  |
                    <a href="https://github.com/allenai/manipulathor">code</a>
                </li>

                <li class="publication"><b>What Can You Learn from Your Muscles? Learning Visual Representation from Human Interactions</b><br/>
                    <i>Kiana Ehsani, Daniel Gordon, Thomas Nguyen, Roozbeh Mottaghi, Ali Farhadi</i><br/>
                    <b>ICLR 2021</b><br/>
                    <a href="https://arxiv.org/abs/2010.08539">pdf</a> |
                    <a href="https://github.com/ehsanik/muscleTorch">code</a>
                </li>
                <li class="publication"><b>Learning Generalizable Visual Representations via Interactive Gameplay</b><br/>
                    <i>Luca Weihs, Aniruddha Kembhavi, Kiana Ehsani, Sarah Pratt, Winson Han, Alvaro Herrasti, Eric Kolve, Dustin Schwenk, Roozbeh Mottaghi, Ali Farhadi</i><br/>
                    <b>ICLR 2021</b><br/>
                    <a href="https://openreview.net/forum?id=UuchYL8wSZo">pdf</a>
                </li>
                <li class="publication"><b>MultiModalQA: complex question answering over text, tables and images</b><br/>
                    <i>Alon Talmor, Ori Yoran, Amnon Catav, Dan Lahav, Yizhong Wang, Akari Asai, Gabriel Ilharco, Hannaneh Hajishirzi, Jonathan Berant</i><br/>
                    <b>ICLR 2021</b><br/>
                    <a href="https://openreview.net/forum?id=ee6W5UgQLa">pdf</a>
                </li>
                <li class="publication"><b>Layer-Wise Data-Free CNN Compression</b><br/>
                    <i>	Maxwell Horton, Yanzi Jin, Ali Farhadi, Mohammad Rastegari</i><br/>
                    <a href="https://arxiv.org/abs/2011.09058">pdf</a>
                </li>
                <li class="publication"><b>AllenAct: A Framework for Embodied AI Research</b><br/>
                    <i>Luca Weihs, Jordi Salvador, Klemen Kotar, Unnat Jain, Kuo-Hao Zeng, Roozbeh Mottaghi, Aniruddha Kembhavi</i>
                    <br/>
                    <a href="https://arxiv.org/abs/2008.12760">pdf</a> |
                    <a href="https://github.com/allenai/allenact">code</a> |
                    <a href="https://allenact.org/">project page</a>
                </li>
                <li class="publication"><b>Are We Overfitting to Experimental Setups in Recognition?</b><br/>
                    <i>Matthew Wallingford, Aditya Kusupati*, Keivan Alizadeh-Vahid*, Aaron Walsman, Aniruddha Kembhavi, Ali Farhadi</i>
                    <br/>
                    <a href="https://arxiv.org/abs/2007.02519">pdf</a> |
                    <a href="https://github.com/RAIVNLab/InTheWild">code</a> |
                    <a href="https://raivn.cs.washington.edu/projects/FLUID">project page</a>
                </li>
                <li class="publication"><b>Watching the World Go By: Representation Learning from Unlabeled
                    Videos</b><br/>
                    <i>Daniel Gordon, Kiana Ehsani, Dieter Fox, Ali Farhadi</i><br/>
                    <a href="https://arxiv.org/abs/2003.07990">pdf</a> |
                    <a href="https://danielgordon10.github.io/papers/vince.html">project page</a> |
                    <a href="https://github.com/danielgordon10/vince">code</a>
                </li>

                <li class="publication"><b>Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping</b><br/>
                    <i>Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali Farhadi, Hannaneh Hajishirzi, Noah
                        Smith</i><br/>
                    <a href="https://arxiv.org/abs/2002.06305">pdf</a>
                </li>

            </ul>
            <h2>2020</h2>
            <ul>
                <li class="publication"><b>Natural Language Rationales with Full-Stack Visual Reasoning: From Pixels to Semantic Frames to Commonsense Graphs</b><br/>
                    <i>Ana Marasovic, Chandra Bhagavatula, Jae Sung Park, Ronan Le Bras, Noah A. Smith, Yejin Choi</i><br/>
                    <b>EMNLP (Findings) 2020</b><br/>
                    <a href="https://arxiv.org/abs/2010.07526">pdf</a>
                </li>
                <li class="publication"><b>Multiple Topologies Prediction for Navigation at Unsignalized Intersections</b><br/>
                    <i>Junha Roh*, Christoforos Mavrogiannis*, Rishabh Madan*, Dieter Fox, Siddhartha S. Srinivasa</i><br/>
                    <b>CoRL 2020</b><br/>
                    <a href="https://arxiv.org/abs/2011.03894">pdf</a> |
                    <a href="https://sites.google.com/view/multiple-topologies-prediction">project page</a> |
                    <a href="https://github.com/rohjunha/multiple-topologies-prediction">code</a>
                </li>
                <li class="publication"><b>Supermasks in Superposition</b><br/>
                    <i>Mitchell Wortsman*, Vivek Ramanujan*, Rosanne Liu, Aniruddha Kembhavi, Mohammad Rastegari, Jason Yosinski, Ali Farhadi</i><br/>
                    <b>NeurIPS 2020</b><br/>
                    <a href="https://arxiv.org/abs/2006.14769">pdf</a> |
                    <a href="https://github.com/RAIVNLab/supsup">code</a> |
                    <a href="https://mitchellnw.github.io/blog/2020/supsup">blog</a>
                </li>
                <li class="publication"><b>RNNPool: Efficient Non-linear Pooling for RAM Constrained Inference</b><br/>
                    <i>Oindrila Saha, Aditya Kusupati, Harsha Vardhan Simhadri, Manik Varma, Prateek Jain</i><br/>
                    <b>NeurIPS 2020</b><br/>
                    <a href="https://arxiv.org/abs/2002.11921">pdf</a> |
                    <a href="https://github.com/microsoft/EdgeML">code</a>
                </li>

                <li class="publication"><b>A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied Tasks</b><br/>
                    <i>Unnat Jain, Luca Weihs, Eric Kolve, Ali Farhadi, Svetlana Lazebnik, Aniruddha Kembhavi, Alexander Schwing</i><br/>
                    <b>ECCV 2020</b><br/>
                    <a href="https://arxiv.org/abs/2007.04979">pdf</a> |
                    <a href="https://unnat.github.io/cordial-sync">project page</a>
                </li>
                <li class="publication"><b>Visual Commonsense Graphs: Reasoning about the Dynamic Context of a Still Image</b><br/>
                    <i>Jae Sung Park, Chandra Bhagavatula, Roozbeh Mottaghi, Ali Farhadi, Yejin Choi</i><br/>
                    <b>ECCV 2020</b><br/>
                    <a href="https://arxiv.org/abs/2004.10796">pdf</a> |
                    <a href="https://visualcomet.xyz">project page</a>
                </li>
                <li class="publication"><b>Grounded Situation Recognition</b><br/>
                    <i>Sarah Pratt, Mark Yatskar, Luca Weihs, Ali Farhadi, Aniruddha Kembhavi</i><br/>
                    <b>ECCV 2020</b><br/>
                    <a href="https://arxiv.org/abs/2003.12058">pdf</a> |
                    <a href="https://prior.allenai.org/projects/gsr">project page</a>
                </li>
                <li class="publication"><b>Identity Aware Multi-Sentence Video Description</b><br/>
                    <i>Jae Sung Park, Trevor Darrell, Anna Rohrbach</i><br/>
                    <b>ECCV 2020</b><br/>
                    <a href="https://arxiv.org/abs/2008.09791">pdf</a> |
                    <a href="https://sites.google.com/site/describingmovies/lsmdc-2019">project page</a>
                </li>

                <li class="publication"><b>Soft Threshold Weight Reparameterization for Learnable Sparsity</b><br/>
                    <i>Aditya Kusupati, Vivek Ramanujan*, Raghav Somani*, Mitchell Wortsman*, Prateek Jain, Sham Kakade, Ali Farhadi</i><br/>
                    <b>ICML 2020</b><br/>
                    <a href="https://arxiv.org/abs/2002.03231">pdf</a> |
                    <a href="https://github.com/RAIVNLab/STR">code</a> |
                    <a href="https://homes.cs.washington.edu/~kusupati/#Kusupati20">project page</a>
                </li>

                <li class="publication"><b>Adversarial Filters of Dataset Biases</b><br/>
                    <i>Ronan Le Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers, Matthew Peters, Ashish Sabharwal, Yejin Choi</i><br/>
                    <b>ICML 2020</b><br/>
                    <a href="https://arxiv.org/abs/2002.04108">pdf</a>
                </li>

                <li class="publication"><b>What’s Hidden in a Randomly Weighted Neural Network?</b><br/>
                    <i>Vivek Ramanujan*, Mitchell Wortsman*, Aniruddha Kembhavi, Ali Farhadi, Mohammad
                        Rastegari </i><br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/1911.13299">pdf</a> |
                    <a href="https://github.com/allenai/hidden-networks">code</a>
                </li>

                <li class="publication"><b>RoboTHOR: An Open Simulation-to-Real Embodied AI Platform</b><br/>
                    <i>Matt Deitke, Winson Han, Alvaro Herrasti, Aniruddha Kembhavi, Eric Kolve, Roozbeh
                        Mottaghi, Jordi Salvador, Dustin Schwenk, Eli VanderBilt, Mathew Walingford, Luca Weihs,
                        Mark Yatskar, Ali Farhadi</i> <br/>
                    <b>CVPR 2020</b></i><br/>
                    <a href="https://arxiv.org/abs/2004.06799">pdf</a> |
                    <a href="https://ai2thor.allenai.org/robothor/">project page</a>
                </li>

                <li class="publication"><b>Visual Reaction: Learning to Play Catch with Your Drone</b><br/>
                    <i>Kuo-Hao Zeng, Roozbeh Mottaghi, Luca Weihs, Ali Farhadi </i> <br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/1912.02155">pdf</a> |
                    <a href="http://github.com/KuoHaoZeng/Visual_Reaction">code</a>
                </li>

                <li class="publication"><b>Butterfly Transform: An Efficient FFT Based Neural Architecture
                    Design</b><br/>
                    <i>Keivan Alizadeh-Vahid, Anish Prabhu, Ali Farhadi, Mohammad Rastegari</i><br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/1906.02256">pdf</a> |
                    <a href="https://github.com/keivanalizadeh/ButterflyTransform">code</a>
                </li>

                <li class="publication"><b>Use the Force, Luke! Learning to Predict Physical Forces by Simulating
                    Effects</b><br/>
                    <i>Kiana Ehsani, Shubham Tulsiani, Saurabh Gupta, Ali Farhadi, Abhinav Gupta</i><br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/2003.12045">pdf</a> |
                    <a href="https://ehsanik.github.io/forcecvpr2020/">project page</a> |
                    <a href="https://github.com/ehsanik/touchTorch">code</a>
                </li>

                <li class="publication"><b>ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks</b><br/>
                    <i>Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, Dieter Fox</i><br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/1912.01734">pdf</a> |
                    <a href="https://askforalfred.com/">project page</a> |
                    <a href="https://github.com/askforalfred/alfred">code</a>
                </li>
                <li class="publication"><b>LatentFusion: End-to-End Differentiable Reconstruction and Rendering for Unseen Object Pose Estimation</b><br/>
                    <i>Keunhong Park, Arsalan Mousavian, Yu Xiang, Dieter Fox</i><br/>
                    <b>CVPR 2020</b><br/>
                    <a href="https://arxiv.org/abs/1912.00416">pdf</a> |
                    <a href="https://github.com/NVlabs/latentfusion">code</a>
                </li>
            </ul>
            <h2>2019</h2>
            <ul>
                <li class="publication"><b>Discovering Neural Wirings</b><br/>
                    <i>Mitchel Wortsman, Ali Farhadi, Mohammad Rastegari</i><br/>
                    <b>NeurIPS 2019</b><br/>
                    <a href="https://arxiv.org/abs/1906.00586">pdf</a> |
                    <a href="https://prior.allenai.org/projects/discovering-neural-wirings">project page</a> |
                    <a href="https://github.com/allenai/dnw">code</a> |
                    <a href="https://mitchellnw.github.io/blog/2019/dnw/">blog</a>
                </li>
                <li class="publication"><b>Defending Against Neural Fake news</b><br/>
                    <i>Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, Yejin Choi</i><br/>
                    <b>NeurIPS 2019</b><br/>
                    <a href="https://arxiv.org/abs/1905.12616">pdf</a> |
                    <a href="https://rowanzellers.com/grover/">project page</a> |
                    <a href="http://github.com/rowanz/grover">code</a> |
                    <a href="https://grover.allenai.org/">demo</a> |
                    <a href="https://medium.com/ai2-blog/counteracting-neural-disinformation-with-grover-6cf6690d463b">blog</a>
                </li>
                <li class="publication"><b>Conditional Driving from Natural Language Instructions</b><br/>
                    <i>Junha Roh, Chris Paxton, Andrezej Pronobis, Ali Farhadi, Dieter Fox</i><br/>
                    <b>CoRL 2019</b><br/>
                    <a href="https://arxiv.org/abs/1910.07615">pdf</a> |
                    <a href="https://sites.google.com/view/language-grounded-driving">project page</a> |
                    <a href="https://github.com/rohjunha/language-grounded-driving">code</a>
                </li>
                <li class="publication"><b>Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index</b><br/>
                    <i>Minjoon Seo, J Lee, Tom Kwiatkowski, AP Parikh, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>ACL 2019</b><br/>
                    <a href="https://arxiv.org/abs/1906.05807">pdf</a> |
                    <a href="https://github.com/uwnlp/denspi">code</a>
                </li>
                <li class="publication"><b>HellaSwag: Can a Machine Really Finish Your Sentence?</b><br/>
                    <i>Rowan Zellers, A Holtzman, Yonatan Bisk, Ali Farhadi, Yejin Choi</i><br/>
                    <b>ACL 2019</b><br/>
                    <a href="https://arxiv.org/abs/1905.07830">pdf</a> |
                    <a href="https://rowanzellers.com/hellaswag/">project page</a> |
                    <a href="https://github.com/rowanz/hellaswag">code</a>
                </li>
                <li class="publication"><b>Learning to Learn How to Learn:Self-Adaptive Visual Navigation Using Meta-Learning</b><br/>
                    <i>Mitchell Wortsman, Kiana Ehsani, Mohammad Rastegari, Ali Farhadi, Roozbeh Mottaghi</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1812.00971">pdf</a> |
                    <a href="https://github.com/allenai/savn">code</a>
                </li>
                <li class="publication"><b>From Recognition to Cognition: Visual Commonsense Reasoning</b><br/>
                    <i>Rowan Zellers, Yonatan Bisk, Ali Farhadi, Yejin Choi</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1811.10830">pdf</a> |
                    <a href="https://visualcommonsense.com/">project page</a> |
                    <a href="https://github.com/rowanz/r2c/">code</a>
                </li>
                <li class="publication"><b>OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge</b><br/>
                    <i>Kenneth Marino, Mohammad Rastegari, Ali Farhadi, Roozbeh Mottaghi</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1906.00067">pdf</a>
                </li>
                <li class="publication"><b>Video Relationship Reasoning using Gated Spatio-Temporal Energy Graph</b><br/>
                    <i>Yao-Hung Hubert Tsai, Santosh Divvala, Louis-Philippe Morency, Ruslan Salakhutdinov, Ali Farhadi</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1903.10547">pdf</a>
                </li>
                <li class="publication"><b>ELASTIC: Improving CNNs with Instance Specific Scaling Policies</b><br/>
                    <i>Huiyu Wang, Aniruddha Kembhavi, Ali Farhadi, Alan Yuille, Mohammad Rastegari</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1812.05262">pdf</a>
                </li>
                <li class="publication"><b>Two Body Problem: Collaborative Visual Task Completion</b><br/>
                    <i>Unnat Jain, Luca Weihs, Eric Kolve, Mohammad Rastegari, Svetlana Lazebnik, Ali Farhadi, Alexander Schwing, Aniruddha Kembhavi</i><br/>
                    <b>CVPR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1904.05879">pdf</a>
                </li>
                <li class="publication"><b>SplitNet: Sim2Sim and Task2Task Transfer for Embodied Visual Navigation</b><br/>
                    <i>Daniel Gordon, Abhishek Kadian, Devi Parikh, Judy Hoffman, Dhruv Batra</i><br/>
                    <b>ICCV 2019</b><br/>
                    <a href="https://danielgordon10.github.io/pdfs/splitnet.pdf">pdf</a> |
                    <a href="https://github.com/facebookresearch/splitnet">code</a>
                </li>
                <li class="publication"><b>Shifting the Baseline: Single Modality Performance on Visual Navigation & QA</b><br/>
                    <i>Jesse Thomason, Daniel Gordon, Yonatan Bisk</i><br/>
                    <b>NAACL 2019 Short Papers</b><br/>
                    <a href="https://danielgordon10.github.io/pdfs/shifting_baseline.pdf">pdf</a>
                </li>
                <li class="publication"><b>Visual Semantic Navigation using Scene Priors</b><br/>
                    <i>Wei Yang, Xiaolong Wang, Ali Farhadi, Abhinav Gupta, Roozbeh Mottaghi</i><br/>
                    <b>ICLR 2019</b><br/>
                    <a href="https://arxiv.org/abs/1810.06543">pdf</a>
                </li>
            </ul>
            <h2>2018</h2>
            <ul>
                <li class="publication"><b>What Should I Do Now? Marrying Reinforcement Learning and Symbolic Planning</b><br/>
                    <i>Daniel Gordon, Dieter Fox, Ali Farhadi</i><br/>
                    <a href="https://danielgordon10.github.io/pdfs/hiprl.pdf">pdf</a> |
                    <a href="https://danielgordon10.github.io/papers/hiprl.html">project page</a> |
                    <a href="https://www.youtube.com/watch?v=0TtWJ_0mPfI">video</a>
                </li>
                <li class="publication"><b>Label refinery: Improving imagenet classification through label progression</b><br/>
                    <i>Hessam Bagherinezhad, Maxwell Horton, Mohammad Rastegari, Ali Farhadi</i><br/>
                    <a href="https://arxiv.org/abs/1805.02641">pdf</a> |
                    <a href="https://github.com/hessamb/label-refinery">code</a>
                </li>
                <li class="publication"><b>YOLOv3: An Incremental Improvement</b><br/>
                    <i>Joseph Redmon, Ali Farhadi</i><br/>
                    <a href="https://arxiv.org/abs/1804.02767">pdf</a> |
                    <a href="https://pjreddie.com/darknet/yolo/">project page</a> |
                    <a href="https://www.youtube.com/watch?v=MPU2HistivI">video</a>
                </li>
                <li class="publication"><b>Phrase-Indexed Question Answering: A New Challenge for Scalable Document Comprehension</b><br/>
                    <i>Minjoon Seo, Tom Kwiatkowski, Ankur P. Parikh, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>EMNLP 2018</b><br>
                    <a href="https://arxiv.org/abs/1804.07726">pdf</a> |
                    <a href="https://github.com/uwnlp/piqa">code</a>
                </li>
                <li class="publication"><b>PhotoShape: Photorealistic Materials for Large-Scale Shape Collections</b><br/>
                    <i>Keunhong Park, Konstantinos Rematas, Ali Farhadi, Steve Seitz</i><br/>
                    <b>SIGGRAPH Asia 2018</b><br>
                    <a href="https://arxiv.org/abs/1809.09761">pdf</a> |
                    <a href="https://keunhong.com/publications/photoshape/">project page</a> |
                    <a href="https://github.com/keunhong/photoshape">code</a>
                </li>
                <li class="publication"><b>Imagine This! Scripts to Compositions to Videos</b><br/>
                    <i>Tanmay Gupta, Dustin Schwenk, Ali Farhadi, Derek Hoiem, Aniruddha Kembhavi</i><br/>
                    <b>ECCV 2018</b><br/>
                    <a href="https://arxiv.org/abs/1804.03608">pdf</a>
                </li>
                <li class="publication"><b>Transferring Common-Sense Knowledge for Object Detection</b><br/>
                    <i>Krishna Kumar Singh, Santosh Kumar Divvala, Ali Farhadi, Yong Jae Lee</i><br/>
                    <b>ECCV 2019</b><br/>
                    <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Krishna_Kumar_Singh_Transferring_Common-Sense_Knowledge_ECCV_2018_paper.pdf">pdf</a>
                </li>
                <li class="publication"><b>Who Let The Dogs Out? Modeling Dog Behavior From Visual Data</b><br/>
                    <i>Kiana Ehsani, Hessam Bagherinezhad, Joseph Redmon, Roozbeh Mottaghi, Ali Farhadi</i><br/>
                    <b>CVPR 2018</b><br>
                    <a href="https://arxiv.org/abs/1803.10827">pdf</a> |
                    <a href="https://github.com/ehsanik/dogTorch">code</a>
                </li>
                <li class="publication"><b>Segan: Segmenting and generating the invisible</b><br/>
                    <i>Kiana Ehsani, Roozbeh Mottaghi, Ali Farhadi</i><br/>
                    <b>CVPR 2018</b><br>
                    <a href="https://arxiv.org/abs/1703.10239">pdf</a> |
                    <a href="https://github.com/ehsanik/SeGAN">code</a>
                </li>
                <li class="publication"><b>Actor and Observer: Joint Modeling of First and Third-Person Videos</b><br/>
                    <i>Gunnar Sigurdsson, Abhinav Gupta, Cordelia Schmid, Ali Farhadi, Karteek Alahari</i><br/>
                    <b>CVPR 2018</b><br>
                    <a href="https://arxiv.org/abs/1804.09627">pdf</a>
                </li>
                <li class="publication"><b>Structured Set Matching Networks for One-Shot Part Labeling</b><br/>
                    <i>Jonghyun Choi, Jayant Krishnamurthy, Aniruddha Kembhavi, Ali Farhadi</i><br/>
                    <b>CVPR 2018</b><br>
                    <a href="https://arxiv.org/abs/1712.01867">pdf</a>
                </li>
                <li class="publication"><b>IQA: Visual Question Answering in Interactive Environments</b><br/>
                    <i>Daniel Gordon, Aniruddha Kembhavi, Mohammad Rastegari, Joseph Redmon, Dieter Fox, Ali Farhadi</i><br/>
                    <b>CVPR 2018</b> | <font style="color:green"><b>NVIDIA Pioneering Research Award</b></font><br/>
                    <a href="https://danielgordon10.github.io/pdfs/iqa.pdf">pdf</a> |
                    <a href="https://danielgordon10.github.io/papers/iqa.html">project page</a> |
                    <a href="https://github.com/danielgordon10/thor-iqa-cvpr-2018">code</a> |
                    <a href="https://www.youtube.com/watch?v=pXd3C-1jr98">video</a>
                </li>
                <li class="publication"><b>Neural Speed Reading via Skim-RNN</b><br/>
                    <i>Minjoon Seo, Sewon Min, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>ICLR 2018</b><br>
                    <a href="https://arxiv.org/abs/1711.02085">pdf</a>
                </li>
                <li class="publication"><b>Re3: Real-Time Recurrent Regression Networks for Visual Tracking of Generic Objects</b><br/>
                    <i>Daniel Gordon, Ali Farhadi, Dieter Fox</i><br/>
                    <b>RAL 2018</b> | Presented at ICRA 2018<br/>
                    <a href="https://danielgordon10.github.io/pdfs/re3.pdf">pdf</a> |
                    <a href="https://danielgordon10.github.io/papers/re3.html">project page</a> |
                    <a href="https://gitlab.com/danielgordon10/re3-tensorflow">code</a> |
                    <a href="https://www.youtube.com/watch?v=RByCiOLlxug">video</a> |
                    <a href="https://www.youtube.com/watch?v=mRpvhuuwMiY">GTC Talk</a>
                </li>
                <li class="publication"><b>AJILE Movement Prediction: Multimodal Deep Learning for Natural Human Neural Recordings and Video</b><br/>
                    <i>Nancy Xin Ru Wang, Ali Farhadi, Rajesh Rao, Bingni Brunton</i><br/>
                    <b>AAAI 2018</b><br>
                    <a href="https://arxiv.org/abs/1709.05939">pdf</a>
                </li>
            </ul>
            <h2>2017</h2>
            <ul>
                <li class="publication"><b>AI2-THOR: An Interactive 3D Environment for Visual AI</b><br/>
                    <i>Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt, Luca Weihs, Alvaro Herrasti, Daniel Gordon, Yuke Zhu, Abhinav Gupta, Ali Farhadi</i><br/>
                    <a href="https://arxiv.org/abs/1712.05474">pdf</a> |
                    <a href="https://ai2thor.allenai.org/">project page</a> |
                    <a href="https://github.com/allenai/ai2thor">code</a> |
                    <a href="https://www.youtube.com/watch?v=KcELPpdN770">video</a> |
                    <a href="https://ai2thor.allenai.org/demo/">demo</a>
                </li>
                <li class="publication"><b>Visual Semantic Planning using Deep Successor Representations</b><br/>
                    <i>Daniel Gordon*, Yuke Zhu*, Eric Kolve, Dieter Fox, Li Fei-Fei, Abhinav Gupta, Roozbeh Mottaghi, Ali Farhadi</i><br/>
                    <b>ICCV 2017</b><br/>
                    <a href="https://danielgordon10.github.io/pdfs/vsp.pdf">pdf</a> |
                    <a href="https://www.youtube.com/watch?v=_2pYVw6ATKo">video</a>
                </li>
                <li class="publication"><b>See the Glass Half Full: Reasoning about Liquid Containers, their Volume and Content</b><br/>
                    <i>Roozbeh Mottaghi, Connor Schenck, Dieter Fox, Ali Farhadi</i><br/>
                    <b>ICCV 2017</b><br/>
                    <a href="https://arxiv.org/abs/1701.02718">pdf</a>
                </li>
                <li class="publication"><b>YOLO9000: Better, Faster, Stronger</b><br/>
                    <i>Joseph Redmon, Ali Farhadi</i><br/>
                    <b>CVPR 2017</b> | <font style="color:green"><b>Best Paper Honorable Mention</b></font><br/>
                    <a href="https://arxiv.org/abs/1612.08242">pdf</a> |
                    <a href="https://pjreddie.com/darknet/yolo/">project page</a>
                </li>
                <li class="publication"><b>Are You Smarter Than A Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension</b><br/>
                    <i>Aniruddha Kembhavi, Minjoon Seo, Eric Klove, Dustin Schwenk, Hannaneh Hajishirzi, Ali Farhadi</i><br/>
                    <b>CVPR 2017</b><br/>
                    <a href="http://ai2-website.s3.amazonaws.com/publications/CVPR17_TQA.pdf">pdf</a> |
                    <a href="http://vuchallenge.org/tqa.html">project page</a>
                </li>
                <li class="publication"><b>LCNN: Lookup-based Convolutional Neural Network</b><br/>
                    <i>Hessam Bagherinezhad, Mohammad Rastegari, Ali Farhadi</i><br/>
                    <b>CVPR 2017</b><br/>
                    <a href="https://arxiv.org/abs/1611.06473">pdf</a> |
                    <a href="https://github.com/hessamb/lcnn">code</a>
                </li>
                <li class="publication"><b>Commonly Uncommon: Semantic Sparsity in Situation Recognition</b><br/>
                    <i>Mark Yatskar, Vicente Ordóñez, Luke Zettlemoyer, Ali Farhadi</i><br/>
                    <b>CVPR 2017</b><br/>
                    <a href="https://arxiv.org/abs/1612.00901">pdf</a> |
                    <a href="http://imsitu.org/demo/">demo</a>
                </li>
                <li class="publication"><b>Asynchronous Temporal Fields for Action Recognition</b><br/>
                    <i>Gunnar A Sigurdsson, Santosh Divvala, Ali Farhadi, Abhinav Gupta</i><br/>
                    <b>CVPR 2017</b><br/>
                    <a href="https://arxiv.org/abs/1612.06371">pdf</a>
                </li>
                <li class="publication"><b>Query-Reduction Networks for Question Answering</b><br/>
                    <i>Minjoon Seo, Sewon Min, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>ICLR 2017</b><br/>
                    <a href="https://arxiv.org/abs/1606.04582">pdf</a> |
                    <a href="https://github.com/uwnlp/qrn">code</a>
                </li>
                <li class="publication"><b>Bidirectional Attention Flow for Machine Comprehension</b><br/>
                    <i>Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi</i><br/>
                    <b>ICLR 2017</b><br/>
                    <a href="https://arxiv.org/abs/1611.01603">pdf</a> |
                    <a href="https://allenai.github.io/bi-att-flow/"> project page</a> |
                    <a href="https://github.com/allenai/bi-att-flow">code</a>
                </li>
                <li class="publication"><b>Target-driven visual navigation in indoor scenes using deep reinforcement learning</b><br/>
                    <i>Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph Lim, Abhinav Gupta, Fei-Fei Li, Ali Farhadi</i><br/>
                    <b>ICRA 2017</b><br/>
                    <a href="https://arxiv.org/abs/1609.05143">pdf</a>
                </li>
                <li class="publication"><b>Summarizing unconstrained videos using salient montages</b><br/>
                    <i>Min Sun, Ali Farhadi, Ben Taskar, Steve Seitz</i><br/>
                    <b>TPAMI 2017</b><br/>
                    <a href="https://ieeexplore.ieee.org/document/7779036">pdf</a>
                </li>
                <li class="publication"><b>Semantic Highlight Retrieval and Term Prediction</b><br/>
                    <i>Min Sun , Kuo-Hao Zeng, Yen-Chen Lin, Ali Farhadi</i><br/>
                    <b>TIP 2017</b><br/>
                    <a href="https://ieeexplore.ieee.org/document/7852483">pdf</a>
                </li>
            </ul>
            <h2>2016</h2>
            <ul>
                <li class="publication"><b>XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</b><br/>
                    <i>Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, Ali Farhadi</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="http://arxiv.org/abs/1603.05279">pdf</a> |
                    <a href="https://github.com/allenai/XNOR-Net">code</a>
                </li>
                <li class="publication"><b>Deep3D: Fully Automatic 2D-to-3D Video Conversion with Deep Convolutional Neural Networks</b><br/>
                    <i>Junyuan Xie, Ross B. Girshick, Ali Farhadi</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="https://arxiv.org/abs/1604.03650">pdf</a> |
                    <a href="https://github.com/piiswrong/deep3d">code</a>
                </li>
                <li class="publication"><b>A Diagram Is Worth A Dozen Images</b><br/>
                    <i>Ani Kembhavi, Mike Salvato, Eric Kolve, Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="https://arxiv.org/abs/1603.07396">pdf</a> |
                    <a href="https://github.com/allenai/dqa-net">code</a>
                </li>
                <li class="publication"><b>"What happens if..." Learning to predict the effect of forces in images</b><br/>
                    <i>Roozbeh Mottaghi, Mohammad Rastegari, Abhinav Gupta, Ali Farhadi</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="https://arxiv.org/abs/1603.05600">pdf</a>
                </li>
                <li class="publication"><b>Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding</b><br/>
                    <i>Gunnar Sigurdsson, Gul Varol, Xiaolong Wang, Ali Farhadi, Ivan Laptev, Abhinav Gupta</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="https://arxiv.org/abs/1604.01753">pdf</a> |
                    <a href="http://allenai.org/plato/charades/">project page</a>
                </li>
                <li class="publication"><b>FigureSeer:Parsing Result-Figures in Research Papers</b><br/>
                    <i>Noah Siegel, Santosh Divvala, Ali Farhadi</i><br/>
                    <b>ECCV 2016</b><br/>
                    <a href="http://ai2-website.s3.amazonaws.com/publications/Siegel16eccv.pdf">pdf</a> |
                    <a href="https://prior.allenai.org/projects/figureseer">project page</a>
                </li>
                <li class="publication"><b>You Only Look Once: Unified, Real-Time Object Detection</b><br/>
                    <i>Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi</i><br/>
                    <b>CVPR 2016</b> | <font style="color:green"><b>OpenCV People's Choice Award</b></font><br/>
                    <a href="http://arxiv.org/abs/1506.02640">pdf</a> |
                    <a href="https://pjreddie.com/darknet/yolo/">project page</a>
                </li>
                <li class="publication"><b>Situation Recognition: Visual Semantic Role Labeling for Image Understanding</b><br/>
                    <i>Mark Yatskar, Luke Zettlemoyer, Ali Farhadi</i><br/>
                    <b>CVPR 2016</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/SituationRecognition.pdf">pdf</a> |
                    <a href="https://github.com/my89/SituationCrf">code</a> |
                    <a href="https://github.com/my89/imSitu">dataset</a>
                </li>
                <li class="publication"><b>Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images</b><br/>
                    <i>Roozbeh Mottaghi, Hessam Bagherinezhad, Mohammad Rastegari, Ali Farhadi</i><br/>
                    <b>CVPR 2016</b><br/>
                    <a href="https://arxiv.org/abs/1511.04048">pdf</a> |
                    <a href="http://allenai.org/plato/newtonian-understanding/">project page</a>
                </li>
                <li class="publication"><b>Actions~Transformation</b><br/>
                    <i>Xiaolong Wang, Ali Farhadi, Abhinav Gupta</i><br/>
                    <b>CVPR 2016</b><br/>
                    <a href="https://arxiv.org/abs/1512.00795">pdf</a>
                </li>
                <li class="publication"><b>A Task-Oriented Approach for Cost-sensitive Recognition</b><br/>
                    <i>Roozbeh Mottaghi, Hannaneh Hajishirzi, Ali Farhadi</i><br/>
                    <b>CVPR 2016</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Tasks.pdf">pdf</a>
                </li>
                <li class="publication"><b>Unsupervised Deep Embedding for Clustering Analysis</b><br/>
                    <i>Junyuan Xie, Ross B. Girshick, Ali Farhadi</i><br/>
                    <b>ICML 2016</b><br/>
                    <a href="http://proceedings.mlr.press/v48/xieb16.html">pdf</a> |
                    <a href="https://github.com/piiswrong/dec">code</a>
                </li>
                <li class="publication"><b>Stating the Obvious: Extracting Visual Common Sense Knowledge</b><br/>
                    <i>Mark Yatskar, Vicente Ordóñez, Ali Farhadi</i><br/>
                    <b>NAACL 2016</b><br/>
                    <a href="https://www.aclweb.org/anthology/N16-1023">pdf</a>
                </li>
                <li class="publication"><b>Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects</b><br/>
                    <i>Hessam Bagherinezhad, Hannaneh Hajishirzi, Yejin Choi, Ali Farhadi</i><br/>
                    <b>AAAI 2016</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Abnormality.pdf">pdf</a>
                </li>
                <li class="publication"><b>Toward a Taxonomy and Computational Models of Abnormalities in Images</b><br/>
                    <i>Babak Saleh, Ahmed Elgammal, Jacob Feldman, Ali Farhadi</i><br/>
                    <b>AAAI 2016</b> | <font style="color:green"><b>Best Student Paper Award</b></font><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Tasks.pdf">pdf</a>
                </li>
            </ul>
            <h2>2015</h2>
            <ul>
                <li class="publication"><b>Segment-Phrase Table for Semantic Segmentation, Visual Entailment and Paraphrasing</b><br/>
                    <i>Hamid Izadinia, Fereshteh Sadeghi, Santosh K Divvala, Hannaneh Hajishirzi, Yejin Choi, Ali Farhadi</i><br/>
                    <b>ICCV 2015</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/spt.pdf">pdf</a>
                </li>
                <li class="publication"><b>Generating Notifications for Missing Actions: Don’t forget to turn the lights off!</b><br/>
                    <i>Bilge Soran, Ali Farhadi, Linda Shapiro</i><br/>
                    <b>ICCV 2015</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/alarm-iccv.pdf">pdf</a>
                </li>
                <li class="publication"><b>VISALOGY: Answering Visual Analogy Questions</b><br/>
                    <i>Fereshteh Sadeghi, Larry Zittnick, Ali Farhadi</i><br/>
                    <b>NeurIPS 2015</b><br/>
                    <a href="https://papers.nips.cc/paper/5777-visalogy-answering-visual-analogy-questions">pdf</a>
                </li>
                <li class="publication"><b>Real-Time Grasp Detection Using Convolutional Neural Networks</b><br/>
                    <i>Joseph Redmon, Anelia Angelova</i><br/>
                    <b>ICRA 2015</b><br/>
                    <a href="http://arxiv.org/abs/1506.02640">pdf</a>
                </li>
                <li class="publication"><b>Solving Geometry Problems: Combining Text and Diagram Interpretation</b><br/>
                    <i>Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi, Oren Etzioni, Clint Malcolm</i><br/>
                    <b>EMNLP 2015</b><br/>
                    <a href="https://www.aclweb.org/anthology/D15-1171">pdf</a> |
                    <a href="https://geometry.allenai.org/">project page</a>
                </li>
                <li class="publication"><b>VisKE: Visual Knowledge Extraction and Question Answering by Visual Verification of Relation Phrases</b><br/>
                    <i>Fereshteh Sadeghi, Santosh K Divvala, Ali Farhadi</i><br/>
                    <b>CVPR 2015</b><br/>
                    <a href="http://viske.allenai.org/paper/fsadeghi_VisKE.pdf">pdf</a> |
                    <a href="http://viske.allenai.org/">project page</a>
                </li>
                <li class="publication"><b>Discriminative and Consistent Similarities in Instance-Level Multiple Instance Learning</b><br/>
                    <i>Mohammad Rastegari, Hannaneh Hajishirzi, Ali Farhadi</i><br/>
                    <b>CVPR 2015</b><br/>
                    <a href="http://ssli.ee.washington.edu/~hannaneh/papers/MIL.pdf">pdf</a>
                </li>
                <li class="publication"><b>Learning to Select and Order Vacation Photographs</b><br/>
                    <i>Fereshteh Sadeghi, J Rafael Tena, Ali Farhadi, Leonid Sigal</i><br/>
                    <b>WACV 2015</b><br/>
                    <a href="http://homes.cs.washington.edu/~fsadeghi/papers/fsadeghi_album_wacv15.pdf">pdf</a>
                </li>
            </ul>
            <h2>2014</h2>
            <ul>
                <li class="publication"><b>Learning Everything about Anything: Webly-Supervised Visual Concept Learning</b><br/>
                    <i>Santosh K Divvala, Ali Farhadi, Carlos Guestrin</i><br/>
                    <b>CVPR 2014</b><br/>
                    <a href="http://levan.cs.washington.edu/ngrams/objectNgrams_cvpr14.pdf">pdf</a> |
                    <a href="http://levan.cs.uw.edu/">project page</a>
                </li>
                <li class="publication"><b>Incorporating Scene Context and Object Layout into Appearance Modeling</b><br/>
                    <i>Hamid Izadinia, Fereshteh Sadeghi, Ali Farhadi</i><br/>
                    <b>CVPR 2014</b><br/>
                    <a href="http://grail.cs.washington.edu/pub/papers/izadinia2014isc.pdf">pdf</a>
                </li>
                <li class="publication"><b>Failure Prediction in Vision Systems</b><br/>
                    <i>Peng Zhang, Jiuling Wang, Ali Farhadi, Martial Hebert, Devi Parikh</i><br/>
                    <b>CVPR 2014</b><br/>
                    <a href="http://www.ri.cmu.edu/pub_files/2014/3/predicting_failures_of_vision_systems_CVPR2014.pdf">pdf</a>
                </li>
                <li class="publication"><b>Towards Transparent Systems: Semantic Characterization of Failure Modes</b><br/>
                    <i>Aayush Bansal, Ali Farhadi, Devi Parikh</i><br/>
                    <b>ECCV 2014</b><br/>
                    <a href="http://www.cs.cmu.edu/~aayushb/pubs/characterizing_mistakes_eccv2014.pdf">pdf</a>
                </li>
                <li class="publication"><b>Salient montages from unconstrained videos</b><br/>
                    <i>Min Sun, Ali Farhadi, Ben Taskar, Steve Seitz</i><br/>
                    <b>ECCV 2014</b><br/>
                    <a href="http://grail.cs.washington.edu/pub/papers/sun2014smf.pdf">pdf</a>
                </li>
                <li class="publication"><b>Ranking Domain-Specific Highlights by Analyzing Edited Videos</b><br/>
                    <i>Min Sun, Ali Farhadi, Steve Seitz</i><br/>
                    <b>ECCV 2014</b><br/>
                    <a href="http://grail.cs.washington.edu/pub/papers/sun2014rdh.pdf">pdf</a>
                </li>
                <li class="publication"><b>Diagram Understanding in Geometry Questions</b><br/>
                    <i>Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi, Oren Etzioni</i><br/>
                    <b>AAAI 2014</b><br/>
                    <a href="http://homes.cs.washington.edu/~minjoon/papers/geosolver/diagram_understanding.pdf">pdf</a> |
                    <a href="https://geometry.allenai.org/">project page</a>
                </li>
                <li class="publication"><b>Multi Resolution Language Grounding with Weak Supervision</b><br/>
                    <i>Rik Koncel Kedziorski, Hannaneh Hajishirzi, and Ali Farhadi</i><br/>
                    <b>EMNLP 2014</b><br/>
                    <a href="http://ssli.ee.washington.edu/~hannaneh/segmentation-emnlp14.pdf">pdf</a>
                </li>
                <li class="publication"><b>Action Recognition in the Presence of One Egocentric and Multiple Static Cameras</b><br/>
                    <i>Bilge Soran, Ali Farhadi, Linda Shapiro</i><br/>
                    <b>ACCV 2014</b><br/>
                    <a href="http://homes.cs.washington.edu/~shapiro/accv2014finalpaper.pdf">pdf</a>
                </li>
            </ul>
            <h2>2013</h2>
            <ul>
                <li class="publication"><b>Multi-Attribute Queries: To Merge or Not to Merge?</b><br/>
                    <i>Mohammad Rastegari, Ali Diba, Devi Parikh, Ali Farhadi</i><br/>
                    <b>CVPR 2013</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/MultiAtr_CVPR13.pdf">pdf</a>
                </li>
                <li class="publication"><b>Object-Centric Anomaly Detection by Attribute-Based Reasoning</b><br/>
                    <i>Babak Saleh, Ali Farhadi, Ahmed Elgammal</i><br/>
                    <b>CVPR 2013</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Abnormality_CVPR13.pdf">pdf</a>
                </li>
                <li class="publication"><b>Adding Unlabeled Samples to Categories by Learned Attributes</b><br/>
                    <i>Jonghyun Choi, Mohammad Rastegari, Ali Farhadi, Larry Davis</i><br/>
                    <b>CVPR 2013</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Adding_CVPR13.pdf">pdf</a>
                </li>
            </ul>
            <h2>2012</h2>
            <ul>
                <li class="publication"><b>Attribute Discovery via Predictable Discriminative Binary Codes</b><br/>
                    <i>Mohammad Rastegari, Ali Farhadi, David Forsyth</i><br/>
                    <b>ECCV 2012</b><br/>
                    <a href="http://www.cs.umd.edu/~mrastega/Site/Publications_files/dbc.pdf">pdf</a>
                </li>
                <li class="publication"><b>Semantic Understanding of Proefessional Soccer Commentaries</b><br/>
                    <i>Hannaneh Hajishirzi, Mohammad Rastegari, Ali Farhadi, Jessica Hodgins</i><br/>
                    <b>UAI 2012</b><br/>
                    <a href="http://homes.cs.washington.edu/~hannaneh/soccer-UAI.pdf">pdf</a>
                </li>
                <li class="publication"><b>Building a Dictionary of Image Fragments</b><br/>
                    <i>Zicheng Liao, Ali Farhadi, Yang Wang, Ian Endres, David Forsyth</i><br/>
                    <b>CVPR 2012</b><br/>
                    <a href="http://web.engr.illinois.edu/~liao17/data/fragdict-cvpr12.pdf">pdf</a>
                </li>
            </ul>
            <h2>2011</h2>
            <ul>
                <li class="publication"><b>Understanding Egocentric Activities</b><br/>
                    <i>Alireza Fathi, Ali Farhadi, James Rehg</i><br/>
                    <b>ICCV 2011</b><br/>
                    <a href="http://www.cc.gatech.edu/~afathi3/publication/ICCV11.pdf">pdf</a>
                </li>
                <li class="publication"><b>Recognition Using Visual Phrases</b><br/>
                    <i>Ali Farhadi, Amin Sadeghi</i><br/>
                    <b>CVPR 2011</b> | <font style="color:green"><b>Best Student Paper Award</b></font><br/>
                    <a href="http://vision.cs.uiuc.edu/phrasal/recognition_using_visual_phrases.pdf">pdf</a>
                </li>
                <li class="publication"><b>Using Classification to Protect the Integrity of Spectrum Measurements in White Space Networks</b><br/>
                    <i>Omid Fatemieh, Ali Farhadi, Ranveer Chandra, Carl Gunter</i><br/>
                    <b>NDSS 2011</b><br/>
                    <a href="http://seclab.uiuc.edu/pubs/FatemiehFCG11.pdf">pdf</a>
                </li>
            </ul>
            <h2>2010</h2>
            <ul>
                <li class="publication"><b>Every Picture Tells a Story: Generating Sentences for Images</b><br/>
                    <i>Ali Farhadi, Mohsen Hejrati, Amin Sadeghi, Peter Young, Cyrus Rashtchian, Julia Hockenmaier, David Forsyth</i><br/>
                    <b>ECCV 2010</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/sentence.pdf">pdf</a>
                </li>
                <li class="publication"><b>Attribute-Centric Recognition for Cross-Category Generalization</b><br/>
                    <i>Ali Farhadi, Ian Endres, Derek Hoiem</i><br/>
                    <b>CVPR 2010</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/attributes_2010.pdf">pdf</a>
                </li>
            </ul>
            <h2>2009</h2>
            <ul>
                <li class="publication"><b>A Latent Model of Discriminative Aspect</b><br/>
                    <i>Ali Farhadi, Mostafa Kamali, Ian Endres, David Forsyth</i><br/>
                    <b>ICCV 2009</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/ICCV09_Aspect.pdf">pdf</a>
                </li>
                <li class="publication"><b>Unlabeled Data Improves Word Prediction</b><br/>
                    <i>Nicolas Loeff, Ali Farhadi, Ian Endres, David Forsyth</i><br/>
                    <b>ICCV 2009</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/ICCV09_manifold.pdf">pdf</a>
                </li>
                <li class="publication"><b>Describing Objects by their Attributes</b><br/>
                    <i>Ali Farhadi, Ian Endres, Derek Hoiem, David Forsyth</i><br/>
                    <b>CVPR 2009</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Attributes.pdf">pdf</a>
                </li>
            </ul>
            <h2>2006-2008</h2>
            <ul>
                <li class="publication"><b>Learning to Recognize Activities from a Wrong Viewpoint</b><br/>
                    <i>Ali Farhadi, Mostafa Kamali</i><br/>
                    <b>ECCV 2008</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Activity_transfer.pdf">pdf</a>
                </li>
                <li class="publication"><b>Scene Discovery by Matrix Factorization</b><br/>
                    <i>Nicolas Loeff, Ali Farhadi</i><br/>
                    <b>ECCV 2008</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/scene_discovery.pdf">pdf</a>
                </li>
                <li class="publication"><b>Transfer Learning in Sign Language</b><br/>
                    <i>Ali Farhadi, David Forsyth, Ryan White</i><br/>
                    <b>CVPR 2007</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/Transfer_Learning_ASL.pdf">pdf</a>
                </li>
                <li class="publication"><b>Aligning ASL for Statistical Translation Using a Discriminative Word Model</b><br/>
                    <i>Ali Farhadi, David Forsyth</i><br/>
                    <b>CVPR 2006</b><br/>
                    <a href="https://homes.cs.washington.edu/~ali/papers/ASL_CVPR06.pdf">pdf</a>
                </li>
            </ul>
        </div>
    </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="./js/bootstrap.min.js"></script>


</body>

</html>
